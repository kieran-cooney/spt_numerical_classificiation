{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b626275-a344-4050-b6c1-bc9eeac43ae5",
   "metadata": {},
   "source": [
    "# Gradient descent density matrix learning\n",
    "Created 08/05/2024\n",
    "\n",
    "Objectives:\n",
    "* As seen in [this notebook](gradient_descent.ipynb), gradient descent is struggling with learning the solution, but fine with unitarizing. However we know the solution is a unitarized version of the density matrix. So can we learn the density matrix first, then unitarize?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad0db4d-805c-4403-9d48-c71d523d572f",
   "metadata": {},
   "source": [
    "# Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecb41ea3-927f-4efa-aebe-ce15784aa037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0375bd38-12e1-417a-908a-13fb540081f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24a13885-9dbd-4e5a-abed-9a67af92458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from operator import mul\n",
    "from collections import namedtuple\n",
    "\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a525ec6-f0c8-47ee-8b0b-345bf0ef8bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from tenpy.tools import hdf5_io\n",
    "import tenpy\n",
    "import tenpy.linalg.np_conserved as npc\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "214f688a-c657-4810-b4d1-b1247deff62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7461fe3-41a3-492f-b018-8e32e27a7300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeb48fbe-9ee7-4f88-9a91-b52643b95a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPTOptimization.utils import (\n",
    "    get_right_identity_environment_from_tp_tensor,\n",
    "    get_left_identity_environment_from_tp_tensor,\n",
    "    to_npc_array,\n",
    "    get_physical_dim\n",
    ")\n",
    "\n",
    "from SPTOptimization.SymmetryActionWithBoundaryUnitaries import SymmetryActionWithBoundaryUnitaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd074eb-4e79-4a83-97a0-8f7b14c0d73a",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a073ec4a-1d8d-4786-af9f-11e750b1e3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_1 = r\"../data/interpolated_trivial_to_nontrivial_fermionic_trivial_proj_rep_200_site_dmrg/\"\n",
    "DATA_DIR_2 = r\"../data/interpolated_nontrivial_fermionic_proj_rep_to_nontrivial_proj_rep_200_site_dmrg/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fd5bc67-e5e4-4b8f-a5e4-f5120506f1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file_name(file_name):\n",
    "    interpolation = int(file_name.split('_')[0])/100\n",
    "\n",
    "    return interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d694f0e0-4ab2-4eea-8f21-7177abc2de50",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data_non_triv_proj_rep = dict()\n",
    "energies_non_triv_proj_rep = dict()\n",
    "\n",
    "for local_file_name in list(os.walk(DATA_DIR_2))[0][2]:\n",
    "    f_name = r\"{}/{}\".format(DATA_DIR_2, local_file_name, ignore_unknown=False)\n",
    "\n",
    "    with h5py.File(f_name, 'r') as f:\n",
    "        data = hdf5_io.load_from_hdf5(f)\n",
    "\n",
    "        data_info = parse_file_name(local_file_name)\n",
    "        loaded_data_non_triv_proj_rep[data_info]=data['wavefunction']\n",
    "        energies_non_triv_proj_rep[data_info]=data['energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba498dc9-2751-4168-98fe-4d64f9933c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi = loaded_data_non_triv_proj_rep[0.45]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914eed85-86ca-41c9-9839-a758b596f631",
   "metadata": {},
   "source": [
    "# Definitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63506364-f535-4c0f-8c5f-8839c69f7b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VIRTUAL_BOND_DIM = 30\n",
    "MAX_INTERMEDIATE_VIRTUAL_BOND_DIM = 2*MAX_VIRTUAL_BOND_DIM\n",
    "# MPO bond dim?\n",
    "MAX_MPO_BOND_DIM = 50\n",
    "\n",
    "SVD_CUTOFF = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2700f1-9c35-422c-9f64-c1ebeae21207",
   "metadata": {},
   "source": [
    "Define bosonic symmetries. Label by the group element added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "513d7288-c641-4071-a4a3-652787d1f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_00 = np.array([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 1, 0],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "\n",
    "np_01 = np.array([\n",
    "    [0, 1, 0, 0],\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 0, 0, 1],\n",
    "    [0, 0, 1, 0]\n",
    "])\n",
    "\n",
    "np_10 = np.array([\n",
    "    [0, 0, 1, 0],\n",
    "    [0, 0, 0, 1],\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 1, 0, 0]\n",
    "])\n",
    "\n",
    "np_11 = np.array([\n",
    "    [0, 0, 0, 1],\n",
    "    [0, 0, 1, 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [1, 0, 0, 0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c83907c6-e86f-48af-a2a1-11b250f47e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "bosonic_np_symmetries = [\n",
    "    np_00,\n",
    "    np_01,\n",
    "    np_10,\n",
    "    np_11\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd7c7309-10ee-4834-b153-9a4121462fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "bosonic_npc_symmetries = [\n",
    "    to_npc_array(X) for X in bosonic_np_symmetries\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a78a62e-37eb-4baf-98ba-d6a94d599bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "npc_00 = to_npc_array(np_00)\n",
    "npc_01 = to_npc_array(np_01)\n",
    "npc_10 = to_npc_array(np_10)\n",
    "npc_11 = to_npc_array(np_11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8a3f80-d770-441f-baad-5ab9ac713e51",
   "metadata": {},
   "source": [
    "Define \"fermionic symmetries\". Just identity and JW string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1c64bf0-4b2e-4492-b242-3dae6eb527c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_I = np.array([\n",
    "    [1, 0],\n",
    "    [0, 1]\n",
    "])\n",
    "\n",
    "np_JW = np.array([\n",
    "    [1, 0],\n",
    "    [0, -1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e595ca13-740a-41a3-a658-8831c8f54323",
   "metadata": {},
   "outputs": [],
   "source": [
    "fermionic_np_symmetries = [np_I, np_JW]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e5b6ad0-2496-4072-afe9-c41fc62da40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fermionic_npc_symmetries = [\n",
    "    to_npc_array(X) for X in fermionic_np_symmetries\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2b43b48-e438-4702-8287-f5d27fc47f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "npc_JW = fermionic_npc_symmetries[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9e2f954-c591-4479-ba37-32862c25c660",
   "metadata": {},
   "outputs": [],
   "source": [
    "symmetry_actions = [\n",
    "    [[b, f] for b in bosonic_np_symmetries]\n",
    "    for f in fermionic_np_symmetries\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c945b86-cec1-4b08-930f-1922b7e1bea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_symmetry_actions = [\n",
    "    [[f, b] for b in bosonic_np_symmetries]\n",
    "    for f in fermionic_np_symmetries\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac19b501-4293-4d08-8bb0-35515cd6a093",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = symmetry_actions[0][1]\n",
    "\n",
    "case = SymmetryActionWithBoundaryUnitaries(\n",
    "    psi,\n",
    "    s*40,\n",
    "    left_symmetry_index=60,\n",
    "    left_boundary_unitaries=[np_I, np_00]*1,\n",
    "    right_boundary_unitaries=[np_00, np_I]*1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e7ff810-32b3-4163-9b1b-ca96a282a7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.171141509766298e-28-4.647688751856734e-31j)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case.compute_svd_approximate_expectation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee06cdc-8577-460b-82cb-2110e47c931a",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7500fa8-a1c6-45bf-949b-53a7526a5be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_physical_dim(tensor, p_label='p'):\n",
    "    index = tensor.get_leg_index(p_label)\n",
    "    dim = tensor.shape[index]\n",
    "    return dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba98ff84-8c5c-4f71-aa88-abbe2b839bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpo_frobenius_inner_product(mpo1_tensors, mpo2_tensors=None):\n",
    "    if mpo2_tensors is None:\n",
    "        mpo2_tensors = mpo1_tensors\n",
    "\n",
    "    w1 = mpo1_tensors[0]\n",
    "    dim = get_physical_dim(w1, p_label='p')\n",
    "    w2 = mpo2_tensors[0]\n",
    "\n",
    "    t = npc.tensordot(w1, w2.conj(), [['p', 'p*'], ['p*', 'p']])\n",
    "    #t /= dim\n",
    "\n",
    "    for w1, w2 in zip(mpo1_tensors[1:], mpo2_tensors[1:]):\n",
    "        dim = get_physical_dim(w1, p_label='p')\n",
    "\n",
    "        t = npc.tensordot(t, w1, [['vR', ], ['vL']])\n",
    "        t = npc.tensordot(t, w2.conj(), [['vR*', 'p', 'p*'], ['vL*', 'p*', 'p']])\n",
    "        #t /= dim\n",
    "\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e202c02-6390-49eb-9b99-32147572b6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unitary_order_two_right_tensors(w_tensors):\n",
    "    out = list()\n",
    "\n",
    "    w = w_tensors[-1]\n",
    "    t = npc.tensordot(w, w.conj(), [['p', 'p*'], ['p*', 'p']])\n",
    "\n",
    "    out.append(t)\n",
    "\n",
    "    for w in w_tensors[-2:0:-1]:\n",
    "        t = npc.tensordot(t, w, [['vL',], ['vR']])\n",
    "        t = npc.tensordot(t, w.conj(), [['vL*', 'p', 'p*'], ['vR*', 'p*', 'p']])\n",
    "\n",
    "        out.append(t)\n",
    "\n",
    "    return out[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e12a7b85-584a-4b5c-8c12-039cc8752ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unitary_order_four_right_tensors(w_tensors):\n",
    "    out = list()\n",
    "\n",
    "    w = w_tensors[-1]\n",
    "    t = npc.tensordot(w, w.conj(), [['p',], ['p*',]])\n",
    "    t.ireplace_labels(['vL', 'vL*'], ['vL1', 'vL1*'])\n",
    "    t = npc.tensordot(t, w, [['p',], ['p*',]])\n",
    "    t = npc.tensordot(t, w.conj(), [['p', 'p*'], ['p*', 'p']])\n",
    "    \n",
    "    out.append(t)\n",
    "\n",
    "    for w in w_tensors[-2:0:-1]:\n",
    "        t = npc.tensordot(t, w, [['vL',], ['vR',]])\n",
    "        t = npc.tensordot(t, w.conj(), [['vL*', 'p'], ['vR*', 'p*']])\n",
    "\n",
    "        w = w.replace_label('vL', 'vL1')\n",
    "    \n",
    "        t = npc.tensordot(t, w, [['vL1', 'p',], ['vR', 'p*']])\n",
    "        t = npc.tensordot(t, w.conj(), [['vL1*', 'p', 'p*'], ['vR*', 'p*', 'p']])\n",
    "\n",
    "        out.append(t)\n",
    "\n",
    "    return out[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d16af878-4506-4fd0-8e37-92a6d7e1360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_right_tensors(w_tensors, b_tensors):\n",
    "    out = list()\n",
    "\n",
    "    t = get_right_identity_environment_from_tp_tensor(b_tensors[-1])\n",
    "\n",
    "    out.append(t)\n",
    "\n",
    "    # First site\n",
    "    b = b_tensors[-1]\n",
    "    w = w_tensors[-1]\n",
    "    \n",
    "    t = npc.tensordot(t, b, [['vL',], ['vR',]])\n",
    "    t = npc.tensordot(\n",
    "        t,\n",
    "        w.replace_label('vL', 'vLm'),\n",
    "        [['p',], ['p*',]]\n",
    "    )\n",
    "    t = npc.tensordot(t, b.conj(), [['p', 'vL*',], ['p*', 'vR*',]])\n",
    "\n",
    "    out.append(t)\n",
    "\n",
    "    # Inner sites\n",
    "    for w, b in zip(w_tensors[-2:0:-1], b_tensors[-2:0:-1]):\n",
    "        t = npc.tensordot(t, b, [['vL',], ['vR',]])\n",
    "        t = npc.tensordot(\n",
    "            t,\n",
    "            w.replace_label('vL', 'vLm'),\n",
    "            [['p', 'vLm'], ['p*', 'vR']]\n",
    "        )\n",
    "        t = npc.tensordot(t, b.conj(), [['p', 'vL*',], ['p*', 'vR*',]])\n",
    "    \n",
    "        out.append(t)\n",
    "\n",
    "    # Last site\n",
    "    b = b_tensors[0]\n",
    "    w = w_tensors[0]\n",
    "\n",
    "    t = npc.tensordot(t, b, [['vL',], ['vR',]])\n",
    "    t = npc.tensordot(\n",
    "        t,\n",
    "        w,\n",
    "        [['p', 'vLm'], ['p*', 'vR']]\n",
    "    )\n",
    "    t = npc.tensordot(t, b.conj(), [['p', 'vL*',], ['p*', 'vR*',]])\n",
    "\n",
    "    out.append(t)\n",
    "\n",
    "    return out[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d00873f7-4cfc-4e63-a9bc-bab1678a416a",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f1a65e9-c5d7-412a-b21d-01ecae1d5f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contracted_right_tensors_mpo(w_tensors_1, w_tensors_2):\n",
    "    out = list()\n",
    "\n",
    "    out.append(t)\n",
    "\n",
    "    # First site\n",
    "    w1 = w_tensors_1[-1].replace_label('vL', 'vL1')\n",
    "    w2 = w_tensors_2[-1].replace_label('vL', 'vL2')\n",
    "    \n",
    "    t = npc.tensordot(w1, w2, [['p', 'p*'], ['p*', 'p']])\n",
    "\n",
    "    out.append(t)\n",
    "\n",
    "    # Inner sites\n",
    "    for w1, w2 in zip(w_tensors_1[-2::-1], w_tensors_1[-2::-1]):\n",
    "        w1 = w1.replace_label('vL', 'vL1')\n",
    "        w2 = w2.replace_label('vL', 'vL2')\n",
    "        t = npc.tensordot(t, w1, [['vL1',], ['vR',]])\n",
    "        t = npc.tensordot(\n",
    "            t,\n",
    "            w2,\n",
    "            [['vL2', 'p', 'p*'], ['vR', 'p*', 'p']]\n",
    "        )\n",
    "  \n",
    "        out.append(t)\n",
    "\n",
    "    return out[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1fda53-6670-4188-b86e-d2809f353b43",
   "metadata": {},
   "source": [
    "### Initialize tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6663e659-fb23-426d-afc6-70a00d2984d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_mpo_tensors(mpo_tensors, new_norm):\n",
    "    num_sites = len(mpo_tensors)\n",
    "\n",
    "    old_norm = mpo_frobenius_inner_product(mpo_tensors).real\n",
    "    \n",
    "    scale_factor = np.power(\n",
    "        new_norm/old_norm,\n",
    "        1/(2*num_sites)\n",
    "    )\n",
    "\n",
    "    for i in range(num_sites):\n",
    "        mpo_tensors[i] = scale_factor*mpo_tensors[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c09d507-0f5d-486e-bb5e-22f8d35a9fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_w_tensor(physical_dim, left_virtual_dim=None,\n",
    "                             right_virtual_dim=None):\n",
    "\n",
    "    if (left_virtual_dim is None) and (right_virtual_dim is None):\n",
    "        dims = (physical_dim, physical_dim)\n",
    "    elif (left_virtual_dim is None):\n",
    "        dims = (physical_dim, physical_dim, right_virtual_dim)\n",
    "    elif (right_virtual_dim is None):\n",
    "        dims = (physical_dim, physical_dim, left_virtual_dim)\n",
    "    else: \n",
    "        dims = (\n",
    "            physical_dim,\n",
    "            physical_dim,\n",
    "            left_virtual_dim,\n",
    "            right_virtual_dim\n",
    "        )\n",
    "    \n",
    "    X1 = rng.normal(size=dims)\n",
    "    X2 = 1j*rng.normal(size=dims)\n",
    "    X = X1 + X2\n",
    "\n",
    "        \n",
    "    if (left_virtual_dim is None) and (right_virtual_dim is None):\n",
    "        out = npc.Array.from_ndarray_trivial(X, labels=['p', 'p*'])\n",
    "    elif right_virtual_dim is None:\n",
    "        out = npc.Array.from_ndarray_trivial(X, labels=['p', 'p*', 'vL'])\n",
    "    elif left_virtual_dim is None:\n",
    "        out = npc.Array.from_ndarray_trivial(X, labels=['p', 'p*', 'vR'])\n",
    "    else:\n",
    "        out = npc.Array.from_ndarray_trivial(\n",
    "            X,\n",
    "            labels=['p', 'p*', 'vL', 'vR']\n",
    "        )\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e779de84-d12b-4de3-b9d8-004bdf6e47bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_mpo_tensors(num_sites, norm=None):\n",
    "    \"\"\"\n",
    "    Needs more arguments\n",
    "    \"\"\"\n",
    "\n",
    "    w = generate_random_w_tensor(edge_dims)\n",
    "    w_tensor = npc.Array.from_ndarray_trivial(\n",
    "        w,\n",
    "        labels=['p', 'p*', 'vR']\n",
    "    )\n",
    "\n",
    "    w_tensors = [w_tensor,]\n",
    "\n",
    "    for _ in range(num_sites-2):\n",
    "        w = generate_random_w_tensor(inner_dims)\n",
    "        w_tensor = npc.Array.from_ndarray_trivial(w, labels=['p', 'p*', 'vL', 'vR'])\n",
    "        \n",
    "        w_tensors.append(w_tensor)\n",
    "\n",
    "    w = generate_random_w_tensor(edge_dims)\n",
    "    w_tensor = npc.Array.from_ndarray_trivial(\n",
    "        w,\n",
    "        labels=['p', 'p*', 'vL']\n",
    "    )\n",
    "    w_tensors.append(w_tensor)\n",
    "\n",
    "    if norm is not None:\n",
    "        rescale_mpo_tensors(w_tensors, norm)\n",
    "\n",
    "    return w_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ffba566-177e-46a4-bb02-953f6a6c8250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identity_w_tensor(physical_dim, left_virtual_dim=None, right_virtual_dim=None):\n",
    "    diagonal = np.ones(physical_dim, dtype='complex')\n",
    "    identity_matrix = np.diag(diagonal)\n",
    "    \n",
    "    if (left_virtual_dim is None) and (right_virtual_dim is None):\n",
    "        w_tensor = npc.Array.from_ndarray_trivial(\n",
    "            identity_matrix,\n",
    "            labels=['p', 'p*']\n",
    "        )\n",
    "    elif right_virtual_dim is None:\n",
    "        X = np.zeros(\n",
    "            (physical_dim, physical_dim, left_virtual_dim),\n",
    "            dtype='complex'\n",
    "        )\n",
    "        X[...,0] = identity_matrix\n",
    "        w_tensor = npc.Array.from_ndarray_trivial(\n",
    "            X,\n",
    "            labels=['p', 'p*', 'vL']\n",
    "        )\n",
    "    elif left_virtual_dim is None:\n",
    "        X = np.zeros(\n",
    "            (physical_dim, physical_dim, right_virtual_dim),\n",
    "            dtype='complex'\n",
    "        )\n",
    "        X[...,0] = identity_matrix\n",
    "        w_tensor = npc.Array.from_ndarray_trivial(\n",
    "            X,\n",
    "            labels=['p', 'p*', 'vR']\n",
    "        )\n",
    "    else:\n",
    "        X = np.zeros(\n",
    "            (physical_dim, physical_dim, left_virtual_dim, right_virtual_dim),\n",
    "            dtype='complex'\n",
    "        )\n",
    "        X[...,0,0] = identity_matrix\n",
    "        w_tensor = npc.Array.from_ndarray_trivial(\n",
    "            X,\n",
    "            labels=['p', 'p*', 'vL', 'vR']\n",
    "        )\n",
    "\n",
    "    return w_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e11bd70-f8d2-4254-870c-75620f9da400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_mpo_tensors(physical_dims, virtual_dims):\n",
    "    \"\"\"\n",
    "    Could fold in with get_identity_mpo_tensors\n",
    "    \"\"\"\n",
    "\n",
    "    w_tensors = [\n",
    "        generate_random_w_tensor(p_dim, *v_dims)\n",
    "        for p_dim, v_dims in zip(physical_dims, virtual_dims)\n",
    "    ]\n",
    "\n",
    "    return w_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "416a67d2-bf88-4655-8ffb-c7d7e0afff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identity_mpo_tensors(physical_dims, virtual_dims):\n",
    "    \"\"\"\n",
    "    Needs more comments, docs!\n",
    "\n",
    "    Often physical dims, virtual dims will be the same, so could add\n",
    "    optional behaviour...\n",
    "    \"\"\"\n",
    "\n",
    "    w_tensors = [\n",
    "        get_identity_w_tensor(p_dim, *v_dims)\n",
    "        for p_dim, v_dims in zip(physical_dims, virtual_dims)\n",
    "    ]\n",
    "\n",
    "    return w_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57bf0ac-6b4d-4988-98e7-fe319d6166c1",
   "metadata": {},
   "source": [
    "### ADAM functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ebe448b-1c37-4bb0-ba43-72ee28829714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_components(X):\n",
    "    r, i = (X.real, X.imag)\n",
    "    return r**2 + 1j*(i**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31b74760-623b-4dd4-a319-24e51b4f08f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_root_components(X):\n",
    "    r, i = (X.real, X.imag)\n",
    "    return np.sqrt(r) + 1j*np.sqrt(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91bff15c-8ecf-44a9-995f-b7f4b8f0615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamTenpy:\n",
    "    def __init__(self, alpha=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8):\n",
    "        self.alpha = alpha\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        self.moment_1 = None\n",
    "        self.moment_2 = None\n",
    "\n",
    "    def update(self, grad):\n",
    "        if self.moment_1 is None:\n",
    "            self.moment_1 = (1-self.beta_1)*grad\n",
    "        else:\n",
    "            self.moment_1 = self.beta_1*self.moment_1 + (1-self.beta_1)*grad\n",
    "\n",
    "        grad_squared = grad.unary_blockwise(squared_components)\n",
    "        if self.moment_2 is None:\n",
    "            self.moment_2 = (1-self.beta_2)*grad_squared\n",
    "        else:\n",
    "            self.moment_2 = self.beta_2*self.moment_2 + (1-self.beta_2)*grad_squared\n",
    "\n",
    "        self.moment_1 /= (1-self.beta_1)\n",
    "        self.moment_2 /= (1-self.beta_2)\n",
    "\n",
    "        out_grad_denom = (\n",
    "            self.moment_2\n",
    "            .unary_blockwise(square_root_components)\n",
    "            .unary_blockwise(lambda x: x + (1+1j)*self.epsilon)\n",
    "        )\n",
    "\n",
    "        out_grad = (\n",
    "            self.moment_1\n",
    "            .binary_blockwise(np.divide, out_grad_denom)\n",
    "        )\n",
    "\n",
    "        return self.alpha*out_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2919303-4883-4327-9b56-743be48ebb53",
   "metadata": {},
   "source": [
    "### Sweep function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "94c08580-6ab0-4501-8e41-1517ea118eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpo_tensor_raw_to_gradient(raw_mpo_tensor, gradient_target_tensor):\n",
    "    \"\"\"\n",
    "    Update raw_mpo_tensor calculated to be the gradient by changing leg names\n",
    "    as neeeded so can be easily and consistently added to\n",
    "    gradient_target_tensor.\n",
    "    \"\"\"\n",
    "    leg_labels = raw_mpo_tensor.get_leg_labels()\n",
    "\n",
    "    # First update the virtual legs\n",
    "    old_new_leg_label_pairs = [\n",
    "        ('vL*', 'vR'),\n",
    "        ('vR*', 'vL'),\n",
    "        ('vL1*', 'vR'),\n",
    "        ('vR1*', 'vL'),\n",
    "        ('vLm', 'vR'),\n",
    "        ('vRm', 'vL'),\n",
    "    ]\n",
    "\n",
    "    for old, new in old_new_leg_label_pairs:\n",
    "        if old in leg_labels:\n",
    "            raw_mpo_tensor.ireplace_label(old, new)\n",
    "\n",
    "    # Then create new array to get the physical legs correct.\n",
    "    # Is this consistent? Should set order of leg labels on raw_mpo_tensor\n",
    "    # before casting to array?\n",
    "    out = npc.Array.from_ndarray_trivial(\n",
    "        raw_mpo_tensor.to_ndarray(),\n",
    "        labels=raw_mpo_tensor.get_leg_labels()\n",
    "    )\n",
    "\n",
    "    out.itranspose(gradient_target_tensor.get_leg_labels())\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa8f1c2b-a2fe-4851-b802-2418f619ce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_mpo_score(raw_gradient_mpo_tensor, gradient_target_tensor,\n",
    "                     virtual_legs=[['vL*', 'vR*',], ['vR*', 'vL*',]],\n",
    "                     take_abs=False\n",
    "                    ):\n",
    "    # Calculate \"score\" (just the contraction of the two relevant tensors)\n",
    "    raw_legs, target_legs = virtual_legs\n",
    "\n",
    "    score = npc.tensordot(\n",
    "        raw_gradient_mpo_tensor,\n",
    "        gradient_target_tensor.conj(),\n",
    "        [['p', 'p*', *raw_legs], ['p*', 'p', *target_legs]]\n",
    "    )\n",
    "\n",
    "    if take_abs:\n",
    "        real_score = np.abs(score)\n",
    "    else:\n",
    "        real_score = score.real\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8e63957b-7f82-4ed6-8e64-1f2097e62ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "def mpo_rdm_gradient_descent_sweep(mpo_tensors, b_tensors, total_dimension,\n",
    "    right_overlap_tensors, left_environment, adam_optimizers):\n",
    "    \"\"\"\n",
    "    Really need to tidy this function up...\n",
    "\n",
    "    COMMENT!\n",
    "    \n",
    "    Also get matrix_dim directly from tensors.\n",
    "    \"\"\"\n",
    "    # Initialise list of gradients to be filled\n",
    "    grads = list()\n",
    "\n",
    "    # Initialise variables\n",
    "    right_contracted_mpo_tensors = unitary_order_two_right_tensors(mpo_tensors)\n",
    "    #right_overlap_tensors = overlap_right_tensors(mpo_tensors, b_tensors)\n",
    "    \n",
    "    left_contracted_mpo_tensors = list()\n",
    "    left_overlap_tensors = list()\n",
    "\n",
    "    num_sites = len(mpo_tensors)\n",
    "    assert len(mpo_tensors) == len(b_tensors)\n",
    "\n",
    "    # Leftmost site\n",
    "    w = mpo_tensors[0]\n",
    "    b = b_tensors[0]\n",
    "\n",
    "    t = right_contracted_mpo_tensors[0]\n",
    "\n",
    "    # MPO terms\n",
    "    # Below line should break? Bad leg indices?\n",
    "    grad_mpo = npc.tensordot(t, w, [['vL'], ['vR',]])\n",
    "\n",
    "    grad_mpo = mpo_tensor_raw_to_gradient(grad_mpo, w)\n",
    "    \n",
    "    # Overlap terms\n",
    "    t = right_overlap_tensors[0].conj().replace_label('vLm*', 'vLm')\n",
    "\n",
    "    grad_o = npc.tensordot(t, b, [['vL'], ['vR',]])\n",
    "    grad_o = npc.tensordot(grad_o, b.conj(), [['vL*',], ['vR*',]])\n",
    "    grad_o = npc.tensordot(grad_o, left_environment.conj(), [['vL', 'vL*'], ['vR', 'vR*']])\n",
    "\n",
    "    # Can these add? Do they have the same leg index?\n",
    "    print(grad_mpo)\n",
    "    print(grad_o)\n",
    "    grad = grad_mpo - grad_o\n",
    "\n",
    "    score=update_mpo_score(\n",
    "        grad,\n",
    "        w,\n",
    "        [['vLm',], ['vR*',]],\n",
    "        take_abs=True\n",
    "    )\n",
    "    adam_grad = adam_optimizers[0].update(grad)\n",
    "    grads.append(adam_grad)\n",
    "\n",
    "    # Create and save left tensors\n",
    "    t = npc.tensordot(w, w.conj(), [['p', 'p*'], ['p*', 'p']])\n",
    "    left_contracted_mpo_tensors.append(t)\n",
    "\n",
    "    t = npc.tensordot(b, w.conj(), [['p',], ['p*',]])\n",
    "    #print(t)\n",
    "    t.ireplace_label('vR*', 'vRm')\n",
    "    #print(t)\n",
    "    t = npc.tensordot(t, left_environment.conj(), [['vL',], ['vR',]])\n",
    "    #print(t)\n",
    "    t = npc.tensordot(t, b.conj(), [['vR*', 'p'], ['vL*', 'p*']])\n",
    "\n",
    "    #print(t)\n",
    "\n",
    "    left_overlap_tensors.append(t)\n",
    "\n",
    "    # Inner sites\n",
    "    for i in range(1, num_sites-1):\n",
    "        w = mpo_tensors[i]\n",
    "        b = b_tensors[i]\n",
    "    \n",
    "        right_two_tensor = right_contracted_mpo_tensors[i]\n",
    "        right_overlap_tensor = right_overlap_tensors[i].conj().replace_label('vLm*', 'vLm')\n",
    "\n",
    "        # Order two terms\n",
    "        left_two_tensor = left_contracted_mpo_tensors[-1]\n",
    "\n",
    "        grad_mpo = npc.tensordot(right_two_tensor, w, [['vL'], ['vR',]])\n",
    "        grad_mpo = npc.tensordot(grad_mpo, left_two_tensor, [['vL'], ['vR',]])\n",
    "\n",
    "        grad_mpo = mpo_tensor_raw_to_gradient(grad_mpo, w)\n",
    "    \n",
    "        # Overlap terms\n",
    "        left_overlap_tensor = left_overlap_tensors[-1]\n",
    "\n",
    "        grad_o = npc.tensordot(right_overlap_tensor, b, [['vL',], ['vR',]])\n",
    "        grad_o = npc.tensordot(grad_o, b.conj(), [['vL*',], ['vR*',]])\n",
    "        grad_o = npc.tensordot(\n",
    "            grad_o,\n",
    "            left_overlap_tensor,\n",
    "            [['vL*', 'vL'], ['vR', 'vR*',]]\n",
    "        )\n",
    "\n",
    "        grad_o = mpo_tensor_raw_to_gradient(grad_o, w)\n",
    "\n",
    "        grad = (grad_mpo - grad_o)\n",
    "\n",
    "        adam_grad = adam_optimizers[i].update(grad)\n",
    "        grads.append(adam_grad)\n",
    "\n",
    "        # Update left tensors\n",
    "        t = npc.tensordot(left_two_tensor, w, [['vR',], ['vL']])\n",
    "        t = npc.tensordot(\n",
    "            t,\n",
    "            w.conj(),\n",
    "            [['vR*', 'p', 'p*'], ['vL*', 'p*', 'p']]\n",
    "        )\n",
    "        \n",
    "        left_contracted_mpo_tensors.append(t)\n",
    "\n",
    "        t = left_overlap_tensor.ireplace_label('vR*', 'vR1*')\n",
    "        t = npc.tensordot(\n",
    "            left_overlap_tensor,\n",
    "            w.conj(),\n",
    "            [['vRm',], ['vL*']]\n",
    "        )\n",
    "        t.ireplace_label('vR*', 'vRm')\n",
    "        t = npc.tensordot(t, b, [['vR', 'p*'], ['vL', 'p']])\n",
    "        t = npc.tensordot(t, b.conj(), [['vR1*', 'p'], ['vL*', 'p*']])\n",
    "\n",
    "        left_overlap_tensors.append(t)\n",
    "\n",
    "    # Last site\n",
    "    left_two_tensor = left_unitary_two_tensors[-1]\n",
    "    w = mpo_tensors[-1]\n",
    "    b = b_tensors[-1]\n",
    "    \n",
    "    grad_mpo = npc.tensordot(left_two_tensor, w, [['vR'], ['vL',]])\n",
    "    grad_mpo = mpo_tensor_raw_to_gradient(grad_mpo, w)\n",
    "\n",
    "    left_overlap_tensor = left_overlap_tensors[-1]\n",
    "    right_overlap_tensor = right_overlap_tensors[-1].conj()\n",
    "\n",
    "    grad_o = npc.tensordot(right_overlap_tensor, b, [['vL',], ['vR',]])\n",
    "    grad_o = npc.tensordot(grad_o, b.conj(), [['vL*',], ['vR*',]])\n",
    "    grad_o = npc.tensordot(\n",
    "        grad_o,\n",
    "        left_overlap_tensor,\n",
    "        [['vL*', 'vL'], ['vR', 'vR*',]]\n",
    "    )\n",
    "\n",
    "    grad_o = mpo_tensor_raw_to_gradient(grad_o, w)\n",
    "\n",
    "    grad = (grad_mpo - grad_o)\n",
    "    adam_grad = adam_optimizers[-1].update(grad)\n",
    "    grads.append(adam_grad)\n",
    "\n",
    "    \"\"\"\n",
    "    for i, g in enumerate(grads):\n",
    "        mpo_tensors[i] = mpo_tensors[i] - g\n",
    "    \"\"\"\n",
    "    \n",
    "    return (grads, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a35f4a5f-aa5f-49e7-a87b-c271d442025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpo_gradient_descent_sweep(mpo_tensors, b_tensors, total_dimension,\n",
    "    right_overlap_tensors, unitarity_learning_rate, overlap_learning_rate,\n",
    "    overlap_target, left_environment, adam_optimizers):\n",
    "    \"\"\"\n",
    "    Really need to tidy this function up...\n",
    "\n",
    "    Also get matrix_dim directly from tensors.\n",
    "    \"\"\"\n",
    "    # Initialise list of gradients to be filled\n",
    "    grads = list()\n",
    "\n",
    "    # Initialise variables\n",
    "    right_unitary_two_tensors = unitary_order_two_right_tensors(mpo_tensors)\n",
    "    right_unitary_four_tensors = unitary_order_four_right_tensors(mpo_tensors)\n",
    "    \n",
    "    left_unitary_two_tensors = list()\n",
    "    left_unitary_four_tensors = list()\n",
    "    left_overlap_tensors = list()\n",
    "\n",
    "    num_sites = len(mpo_tensors)\n",
    "    assert len(mpo_tensors) == len(b_tensors)\n",
    "\n",
    "    # Leftmost site\n",
    "    w = mpo_tensors[0]\n",
    "    b = b_tensors[0]\n",
    "\n",
    "    t = right_unitary_two_tensors[0]\n",
    "\n",
    "    # Second order terms\n",
    "    grad_2 = npc.tensordot(t, w, [['vL'], ['vR',]])\n",
    "\n",
    "    order_2_score = update_mpo_score(\n",
    "        grad_2,\n",
    "        w,\n",
    "        [['vL*',], ['vR*',]]\n",
    "    )\n",
    "\n",
    "    grad_2 = mpo_tensor_raw_to_gradient(grad_2, w)\n",
    "\n",
    "    # Fourth order terms\n",
    "    t = right_unitary_four_tensors[0]\n",
    "\n",
    "    grad_4 = npc.tensordot(t, w, [['vL'], ['vR',]])\n",
    "    grad_4 = npc.tensordot(grad_4, w.conj(), [['vL*', 'p'], ['vR*', 'p*']])\n",
    "    grad_4 = npc.tensordot(grad_4, w, [['vL1', 'p'], ['vR', 'p*']])\n",
    "\n",
    "    order_4_score = update_mpo_score(\n",
    "        grad_4,\n",
    "        w,\n",
    "        [['vL1*',], ['vR*',]]\n",
    "    )\n",
    "\n",
    "    grad_4 = mpo_tensor_raw_to_gradient(grad_4, w)\n",
    "\n",
    "    unitary_score = order_4_score - 2*order_2_score + total_dimension\n",
    "    unitary_grad = (grad_4 - grad_2)/np.sqrt(1+unitary_score)\n",
    "    \n",
    "    # Overlap terms\n",
    "    t = right_overlap_tensors[0].conj().replace_label('vLm*', 'vLm')\n",
    "\n",
    "    grad_o = npc.tensordot(t, b, [['vL'], ['vR',]])\n",
    "    grad_o = npc.tensordot(grad_o, b.conj(), [['vL*',], ['vR*',]])\n",
    "    grad_o = npc.tensordot(grad_o, left_environment, [['vL', 'vL*'], ['vR', 'vR*']])\n",
    "\n",
    "    c_conj = update_mpo_score(\n",
    "        grad_o,\n",
    "        w,\n",
    "        [['vLm',], ['vR*',]],\n",
    "        take_abs=True\n",
    "    )\n",
    "    c = c_conj.conjugate()\n",
    "    c_abs = np.abs(c)\n",
    "    \n",
    "    grad_o_scale = c*(1 - overlap_target/c_abs)\n",
    "    grad_o = grad_o_scale*grad_o\n",
    "    grad_o = mpo_tensor_raw_to_gradient(grad_o, w)\n",
    "\n",
    "    grad = (\n",
    "        unitarity_learning_rate*unitary_grad +\n",
    "        overlap_learning_rate*grad_o\n",
    "    )\n",
    "    adam_grad = adam_optimizers[0].update(grad)\n",
    "    grads.append(adam_grad)\n",
    "\n",
    "    # Create and save left tensors\n",
    "    t = npc.tensordot(w, w.conj(), [['p', 'p*'], ['p*', 'p']])\n",
    "    left_unitary_two_tensors.append(t)\n",
    "    \n",
    "    t = npc.tensordot(w, w.conj(), [['p',], ['p*',]])\n",
    "    t.ireplace_labels(['vR', 'vR*'], ['vR1', 'vR1*'])\n",
    "    t = npc.tensordot(t, w, [['p',], ['p*',]])\n",
    "    t = npc.tensordot(t, w.conj(), [['p', 'p*'], ['p*', 'p']])\n",
    "    \n",
    "    left_unitary_four_tensors.append(t)\n",
    "\n",
    "    t = npc.tensordot(b, w.conj(), [['p',], ['p*',]])\n",
    "    #print(t)\n",
    "    t.ireplace_label('vR*', 'vRm')\n",
    "    #print(t)\n",
    "    t = npc.tensordot(t, left_environment, [['vL',], ['vR',]])\n",
    "    #print(t)\n",
    "    t = npc.tensordot(t, b.conj(), [['vR*', 'p'], ['vL*', 'p*']])\n",
    "\n",
    "    #print(t)\n",
    "\n",
    "    left_overlap_tensors.append(t)\n",
    "\n",
    "    # Inner sites\n",
    "    for i in range(1, num_sites-1):\n",
    "        w = mpo_tensors[i]\n",
    "        b = b_tensors[i]\n",
    "    \n",
    "        right_two_tensor = right_unitary_two_tensors[i]\n",
    "        right_four_tensor = right_unitary_four_tensors[i]\n",
    "        right_overlap_tensor = right_overlap_tensors[i].conj().replace_label('vLm*', 'vLm')\n",
    "\n",
    "        # Order two terms\n",
    "        left_two_tensor = left_unitary_two_tensors[-1]\n",
    "\n",
    "        grad_2 = npc.tensordot(right_two_tensor, w, [['vL'], ['vR',]])\n",
    "        grad_2 = npc.tensordot(grad_2, left_two_tensor, [['vL'], ['vR',]])\n",
    "\n",
    "        grad_2 = mpo_tensor_raw_to_gradient(grad_2, w)\n",
    "\n",
    "        # Order four terms\n",
    "        left_four_tensor = left_unitary_four_tensors[-1]\n",
    "\n",
    "        grad_4 = npc.tensordot(right_four_tensor, w, [['vL'], ['vR',]])\n",
    "        grad_4 = npc.tensordot(grad_4, w.conj(), [['vL*', 'p'], ['vR*', 'p*']])\n",
    "\n",
    "        grad_4 = npc.tensordot(\n",
    "            grad_4,\n",
    "            w.replace_label('vL', 'vL1'),\n",
    "            [['vL1', 'p'], ['vR', 'p*']]\n",
    "        )\n",
    "\n",
    "        grad_4 = npc.tensordot(\n",
    "            grad_4,\n",
    "            left_four_tensor,\n",
    "            [['vL', 'vL*', 'vL1'], ['vR', 'vR*', 'vR1']]\n",
    "        )\n",
    "\n",
    "        grad_4 = mpo_tensor_raw_to_gradient(grad_4, w)\n",
    "\n",
    "        unitary_grad = (grad_4 - grad_2)/np.sqrt(1+unitary_score)\n",
    "    \n",
    "        # Overlap terms\n",
    "        left_overlap_tensor = left_overlap_tensors[-1]\n",
    "\n",
    "        grad_o = npc.tensordot(right_overlap_tensor, b, [['vL',], ['vR',]])\n",
    "        grad_o = npc.tensordot(grad_o, b.conj(), [['vL*',], ['vR*',]])\n",
    "        grad_o = npc.tensordot(\n",
    "            grad_o,\n",
    "            left_overlap_tensor,\n",
    "            [['vL*', 'vL'], ['vR', 'vR*',]]\n",
    "        )\n",
    "\n",
    "        grad_o = grad_o_scale*grad_o\n",
    "        grad_o = mpo_tensor_raw_to_gradient(grad_o, w)\n",
    "\n",
    "        grad = (\n",
    "            unitarity_learning_rate*unitary_grad +\n",
    "            overlap_learning_rate*grad_o\n",
    "        )\n",
    "        adam_grad = adam_optimizers[i].update(grad)\n",
    "        grads.append(adam_grad)\n",
    "\n",
    "        # Update left tensors\n",
    "        t = npc.tensordot(left_two_tensor, w, [['vR',], ['vL']])\n",
    "        t = npc.tensordot(\n",
    "            t,\n",
    "            w.conj(),\n",
    "            [['vR*', 'p', 'p*'], ['vL*', 'p*', 'p']]\n",
    "        )\n",
    "        \n",
    "        left_unitary_two_tensors.append(t)\n",
    "        \n",
    "        t = npc.tensordot(left_four_tensor, w, [['vR',], ['vL']])\n",
    "        t = npc.tensordot(t, w.conj(), [['vR*', 'p'], ['vL*', 'p*']])\n",
    "        t = npc.tensordot(\n",
    "            t,\n",
    "            w.replace_label('vR', 'vR1'),\n",
    "            [['p', 'vR1'], ['p*', 'vL']]\n",
    "        )\n",
    "        t = npc.tensordot(\n",
    "            t,\n",
    "            w.conj().replace_label('vR*', 'vR1*'),\n",
    "            [['p', 'p*', 'vR1*'], ['p*', 'p', 'vL*']]\n",
    "        )\n",
    "        \n",
    "        left_unitary_four_tensors.append(t)\n",
    "\n",
    "        t = left_overlap_tensor.ireplace_label('vR*', 'vR1*')\n",
    "        t = npc.tensordot(\n",
    "            left_overlap_tensor,\n",
    "            w.conj(),\n",
    "            [['vRm',], ['vL*']]\n",
    "        )\n",
    "        t.ireplace_label('vR*', 'vRm')\n",
    "        t = npc.tensordot(t, b, [['vR', 'p*'], ['vL', 'p']])\n",
    "        t = npc.tensordot(t, b.conj(), [['vR1*', 'p'], ['vL*', 'p*']])\n",
    "\n",
    "        left_overlap_tensors.append(t)\n",
    "\n",
    "    # Last site\n",
    "    left_two_tensor = left_unitary_two_tensors[-1]\n",
    "    w = mpo_tensors[-1]\n",
    "    b = b_tensors[-1]\n",
    "    \n",
    "    grad_2 = npc.tensordot(left_two_tensor, w, [['vR'], ['vL',]])\n",
    "    grad_2 = mpo_tensor_raw_to_gradient(grad_2, w)\n",
    "\n",
    "    left_four_tensor = left_unitary_four_tensors[-1]\n",
    "    \n",
    "    grad_4 = npc.tensordot(left_four_tensor, w, [['vR'], ['vL',]])\n",
    "    grad_4 = npc.tensordot(grad_4, w.conj(), [['vR*', 'p'], ['vL*', 'p*']])\n",
    "    grad_4 = npc.tensordot(grad_4, w, [['vR1', 'p'], ['vL', 'p*']])\n",
    "\n",
    "    grad_4 = mpo_tensor_raw_to_gradient(grad_4, w)\n",
    "    \n",
    "    unitary_grad = (grad_4 - grad_2)/np.sqrt(1+unitary_score)\n",
    "\n",
    "    left_overlap_tensor = left_overlap_tensors[-1]\n",
    "    right_overlap_tensor = right_overlap_tensors[-1].conj()\n",
    "\n",
    "    grad_o = npc.tensordot(right_overlap_tensor, b, [['vL',], ['vR',]])\n",
    "    grad_o = npc.tensordot(grad_o, b.conj(), [['vL*',], ['vR*',]])\n",
    "    grad_o = npc.tensordot(\n",
    "        grad_o,\n",
    "        left_overlap_tensor,\n",
    "        [['vL*', 'vL'], ['vR', 'vR*',]]\n",
    "    )\n",
    "\n",
    "    grad_o = grad_o_scale*grad_o\n",
    "    grad_o = mpo_tensor_raw_to_gradient(grad_o, w)\n",
    "\n",
    "\n",
    "    grad = (\n",
    "        unitarity_learning_rate*unitary_grad +\n",
    "        overlap_learning_rate*grad_o\n",
    "    )\n",
    "    adam_grad = adam_optimizers[-1].update(grad)\n",
    "    grads.append(adam_grad)\n",
    "\n",
    "    \"\"\"\n",
    "    for i, g in enumerate(grads):\n",
    "        mpo_tensors[i] = mpo_tensors[i] - g\n",
    "    \"\"\"\n",
    "    \n",
    "    return (grads, unitary_score, c_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4c0c3f6-9014-41c6-a7b3-745dd0dc9970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_left_right_indices(npc_array):\n",
    "    left_right_pairs = {\n",
    "        'vL': 'vR',\n",
    "        'vR': 'vL',\n",
    "        'vL*': 'vR*',\n",
    "        'vR*': 'vL*'\n",
    "    }\n",
    "\n",
    "    leg_labels = npc_array.get_leg_labels()\n",
    "\n",
    "    old_labels = [l for l in leg_labels if l in left_right_pairs]\n",
    "    new_labels = [left_right_pairs[l] for l in old_labels]\n",
    "\n",
    "    out = npc_array.replace_labels(old_labels, new_labels)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "609258af-7f4f-4589-9000-34615d59d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_sided_mpo_rdm_gradient_descent_sweep(left_mpo_tensors, right_mpo_tensors,\n",
    "    left_b_tensors, right_b_tensors, left_total_dimension,\n",
    "    right_total_dimension, symmetry_transfer_matrix, left_adam_optimizers,\n",
    "    right_adam_optimizers):\n",
    "\n",
    "    # Compute left and right symmetry environments\n",
    "    # Right symmetry environment for left side first\n",
    "    right_overlap_tensors = overlap_right_tensors(\n",
    "        right_mpo_tensors,\n",
    "        right_b_tensors\n",
    "    )\n",
    "    right_symmetry_environment = npc.tensordot(\n",
    "        symmetry_transfer_matrix,\n",
    "        right_overlap_tensors[0],\n",
    "        [['vR', 'vR*'], ['vL', 'vL*']]\n",
    "    )\n",
    "    right_symmetry_environment = swap_left_right_indices(right_symmetry_environment)\n",
    "\n",
    "    # Left symmetry environment for right side\n",
    "    left_overlap_tensors = overlap_right_tensors(\n",
    "        left_mpo_tensors,\n",
    "        left_b_tensors\n",
    "    )\n",
    "    left_symmetry_environment = npc.tensordot(\n",
    "        symmetry_transfer_matrix,\n",
    "        swap_left_right_indices(left_overlap_tensors[0]),\n",
    "        [['vL', 'vL*'], ['vR', 'vR*']]\n",
    "    )\n",
    "\n",
    "    # Get right gradients\n",
    "    right_grads, score = mpo_rdm_gradient_descent_sweep(\n",
    "        right_mpo_tensors,\n",
    "        right_b_tensors,\n",
    "        right_total_dimension,\n",
    "        right_overlap_tensors[1:],\n",
    "        left_symmetry_environment,\n",
    "        right_adam_optimizers\n",
    "    )\n",
    "    \n",
    "    for i, g in enumerate(right_grads):\n",
    "        right_mpo_tensors[i] = right_mpo_tensors[i] - g\n",
    "\n",
    "    # Get left gradients\n",
    "    left_grads, *_  = mpo_rdm_gradient_descent_sweep(\n",
    "        left_mpo_tensors,\n",
    "        left_b_tensors,\n",
    "        left_total_dimension,\n",
    "        left_overlap_tensors[1:],\n",
    "        right_symmetry_environment,\n",
    "        left_adam_optimizers\n",
    "    )\n",
    "\n",
    "    for i, g in enumerate(left_grads):\n",
    "        left_mpo_tensors[i] = left_mpo_tensors[i] - g\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d66c2c04-401a-4cf8-8f7a-a2745f3c3a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_sided_mpo_gradient_descent_sweep(left_mpo_tensors, right_mpo_tensors,\n",
    "    left_b_tensors, right_b_tensors, left_total_dimension,\n",
    "    right_total_dimension, unitarity_learning_rate, overlap_learning_rate,\n",
    "    symmetry_transfer_matrix, left_adam_optimizers, right_adam_optimizers):\n",
    "\n",
    "    # Compute left and right symmetry environments\n",
    "    # Right symmetry environment for left side first\n",
    "    right_overlap_tensors = overlap_right_tensors(\n",
    "        right_mpo_tensors,\n",
    "        right_b_tensors\n",
    "    )\n",
    "    right_symmetry_environment = npc.tensordot(\n",
    "        symmetry_transfer_matrix,\n",
    "        right_overlap_tensors[0],\n",
    "        [['vR', 'vR*'], ['vL', 'vL*']]\n",
    "    )\n",
    "    right_symmetry_environment = swap_left_right_indices(right_symmetry_environment)\n",
    "\n",
    "    # Left symmetry environment for right side\n",
    "    left_overlap_tensors = overlap_right_tensors(\n",
    "        left_mpo_tensors,\n",
    "        left_b_tensors\n",
    "    )\n",
    "    left_symmetry_environment = npc.tensordot(\n",
    "        symmetry_transfer_matrix,\n",
    "        swap_left_right_indices(left_overlap_tensors[0]),\n",
    "        [['vL', 'vL*'], ['vR', 'vR*']]\n",
    "    )\n",
    "\n",
    "    # Get right gradients\n",
    "    right_grads, unitary_score, c_abs = mpo_gradient_descent_sweep(\n",
    "        right_mpo_tensors,\n",
    "        right_b_tensors,\n",
    "        right_total_dimension,\n",
    "        right_overlap_tensors[1:],\n",
    "        unitarity_learning_rate,\n",
    "        overlap_learning_rate,\n",
    "        1,\n",
    "        left_symmetry_environment,\n",
    "        right_adam_optimizers\n",
    "    )\n",
    "    \n",
    "    for i, g in enumerate(right_grads):\n",
    "        right_mpo_tensors[i] = right_mpo_tensors[i] - g\n",
    "\n",
    "    # Get left gradients\n",
    "    left_grads, *_ = mpo_gradient_descent_sweep(\n",
    "        left_mpo_tensors,\n",
    "        left_b_tensors,\n",
    "        left_total_dimension,\n",
    "        left_overlap_tensors[1:],\n",
    "        unitarity_learning_rate,\n",
    "        overlap_learning_rate,\n",
    "        1,\n",
    "        right_symmetry_environment,\n",
    "        left_adam_optimizers\n",
    "    )\n",
    "\n",
    "    for i, g in enumerate(left_grads):\n",
    "        left_mpo_tensors[i] = left_mpo_tensors[i] - g\n",
    "\n",
    "    return (unitary_score, c_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1a8b9251-44db-4ef2-80ad-db74402a94b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unitarity_error_from_subscores(order_two_score, order_four_score, dimension):\n",
    "    return order_four_score - 2*order_two_score + dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b2ddc829-2e4b-4aa9-9711-b76244621c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unitarity_errors_from_subscores(order_two_scores, order_four_scores,\n",
    "                                    dimension):\n",
    "    out = [\n",
    "        unitarity_error_from_subscores(o2, o4, dimension)\n",
    "        for o2, o4 in zip(order_two_scores, order_four_scores)\n",
    "    ]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e390f713-9369-4353-b585-07ea44412fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_optimization(num_sites, bond_dimension, symmetry_case,\n",
    "    unitarity_learning_rate, overlap_learning_rate, adam_params):\n",
    "    right_b_tensors = [\n",
    "        symmetry_case.psi.get_B(i)\n",
    "        for i in range(\n",
    "            symmetry_case.right_symmetry_index + 1,\n",
    "            symmetry_case.right_symmetry_index + 1 + num_sites\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    left_b_tensors = [\n",
    "        symmetry_case.psi.get_B(i, form='A')\n",
    "        for i in range(\n",
    "            symmetry_case.left_symmetry_index - 1,\n",
    "            symmetry_case.left_symmetry_index - 1 - num_sites, -1\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    left_b_tensors = [\n",
    "        swap_left_right_indices(b) for b in left_b_tensors\n",
    "    ]\n",
    "\n",
    "    right_physical_dims = [\n",
    "        get_physical_dim(b) for b in right_b_tensors\n",
    "    ]\n",
    "    \n",
    "    right_total_dimension = reduce(mul, right_physical_dims)\n",
    "\n",
    "    left_physical_dims = [\n",
    "        get_physical_dim(b) for b in left_b_tensors\n",
    "    ]\n",
    "\n",
    "    left_total_dimension = reduce(mul, left_physical_dims)\n",
    "\n",
    "    virtual_dims = (\n",
    "        [(None, bond_dimension),] +\n",
    "        [(bond_dimension, bond_dimension)]*(num_sites - 2) +\n",
    "        [(bond_dimension, None),]\n",
    "    )\n",
    "\n",
    "    right_mpo_tensors = get_random_mpo_tensors(\n",
    "        right_physical_dims,\n",
    "        virtual_dims\n",
    "    )\n",
    "    left_mpo_tensors = get_random_mpo_tensors(\n",
    "        left_physical_dims,\n",
    "        virtual_dims\n",
    "    )\n",
    "    rescale_mpo_tensors(right_mpo_tensors, 1)\n",
    "    rescale_mpo_tensors(left_mpo_tensors, 1)\n",
    "\n",
    "    symmetry_transfer_matrix = symmetry_case.npc_symmetry_transfer_matrix\n",
    "\n",
    "    left_adam_optimizers = [\n",
    "        AdamTenpy(*adam_params) for _ in range(num_sites)\n",
    "    ]\n",
    "\n",
    "    right_adam_optimizers = [\n",
    "        AdamTenpy(*adam_params) for _ in range(num_sites)\n",
    "    ]\n",
    "\n",
    "    return (\n",
    "        left_mpo_tensors,\n",
    "        right_mpo_tensors,\n",
    "        left_b_tensors,\n",
    "        right_b_tensors,\n",
    "        left_total_dimension,\n",
    "        right_total_dimension,\n",
    "        unitarity_learning_rate,\n",
    "        overlap_learning_rate,\n",
    "        symmetry_transfer_matrix,\n",
    "        left_adam_optimizers,\n",
    "        right_adam_optimizers\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6b77d4-1b5d-455b-9d45-b0dfc2fe378d",
   "metadata": {},
   "source": [
    "### SPT phase extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "19115e31-e566-4904-b863-492184c744e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjugate_single_mpo_tensor(mpo_tensor):\n",
    "    leg_labels = mpo_tensor.get_leg_labels()\n",
    "\n",
    "    if not ('vR' in leg_labels):\n",
    "        return mpo_tensor.conj().replace_labels(['vL*',], ['vL',])\n",
    "    elif not ('vL' in leg_labels):\n",
    "        return mpo_tensor.conj().replace_labels(['vR*'], ['vR'])\n",
    "    else:\n",
    "        return mpo_tensor.conj().replace_labels(['vL*', 'vR*'], ['vL', 'vR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "58405086-22cd-4f65-8eec-0888ff6eb03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjugate_mpo(mpo_tensors):\n",
    "    return [\n",
    "        conjugate_single_mpo_tensor(t) for t in mpo_tensors\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6a0c4ee6-9a5c-464f-b7ba-68adbd5ad640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpo_product_expectation(left_environment, b_tensors, mpos):\n",
    "    \"\"\"\n",
    "    Have an optional b_conj argument? Left and right arguments?\n",
    "\n",
    "    Like a previous function we wrote?\n",
    "    \"\"\"\n",
    "\n",
    "    # First site\n",
    "    t = b_tensors[0]\n",
    "\n",
    "    for i, l in enumerate(mpos):\n",
    "        w = l[0]\n",
    "        t = npc.tensordot(\n",
    "            t,\n",
    "            w.replace_label('vR', f'vR{i}'),\n",
    "            [['p',], ['p*',]]\n",
    "        )\n",
    "\n",
    "    t = npc.tensordot(\n",
    "        t,\n",
    "        b_tensors[0].conj(),\n",
    "        [['p',], ['p*',]]\n",
    "    )\n",
    "\n",
    "    t = npc.tensordot(\n",
    "        t,\n",
    "        left_environment,\n",
    "        [['vL', 'vL*',], ['vR', 'vR*']]\n",
    "    )\n",
    "\n",
    "    # Inner sites\n",
    "    for i in range(1, len(b_tensors)-1):\n",
    "        t = npc.tensordot(\n",
    "            t,\n",
    "            b_tensors[i],\n",
    "            [['vR',], ['vL',]]\n",
    "        )\n",
    "\n",
    "        for j, l in enumerate(mpos):\n",
    "            w = l[i]\n",
    "            t = npc.tensordot(\n",
    "                t,\n",
    "                w.replace_label('vR', f'vR{j}'),\n",
    "                [['p', f'vR{j}'], ['p*', 'vL']]\n",
    "            )\n",
    "    \n",
    "        t = npc.tensordot(\n",
    "            t,\n",
    "            b_tensors[i].conj(),\n",
    "            [['p', 'vR*'], ['p*', 'vL*']]\n",
    "        )\n",
    "\n",
    "    # Last site\n",
    "    t = npc.tensordot(\n",
    "        t,\n",
    "        b_tensors[-1],\n",
    "        [['vR',], ['vL',]]\n",
    "    )\n",
    "\n",
    "    for i, l in enumerate(mpos):\n",
    "        w = l[-1]\n",
    "        t = npc.tensordot(\n",
    "            t,\n",
    "            w,\n",
    "            [['p', f'vR{i}'], ['p*', 'vL']]\n",
    "        )\n",
    "\n",
    "    t = npc.tensordot(\n",
    "        t,\n",
    "        b_tensors[-1].conj(),\n",
    "        [['p', 'vR*', 'vR'], ['p*', 'vL*', 'vR*']]\n",
    "    )\n",
    "\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "86ff850e-a4f7-4b73-9360-03431af04fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj_rep_phase(left_environment, b_tensors, mpo_1, mpo_2, mpo_3):\n",
    "    num = mpo_product_expectation(\n",
    "        left_environment,\n",
    "        b_tensors,\n",
    "        [\n",
    "            mpo_1,\n",
    "            mpo_2,\n",
    "            conjugate_mpo(mpo_3)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    den = npc.trace(left_environment)\n",
    "\n",
    "    return num/den"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c10c2f3-0203-4a02-841e-4ddf5896ec51",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bade0aff-058d-4a67-9f83-87815cadf293",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 1000\n",
    "\n",
    "num_sites = 4\n",
    "bond_dimension=6\n",
    "adam_params = (1e-4, 0.4, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "de84ca52-4502-49e7-bec4-38901dc9a448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<npc.Array shape=(4, 4, 6) labels=['p', 'p*', 'vR']\n",
      "charge=ChargeInfo([], [])\n",
      " +1 | +1 | +1 \n",
      "0 []|0 []|0 []\n",
      "4   |4   |6   \n",
      "[[[-0.03182779+0.11748717j  0.03754959+0.054921j\n",
      "    0.01814555+0.02231885j -0.02341799-0.00779502j\n",
      "   -0.01798294+0.01548427j -0.06625321+0.02238904j]\n",
      "  [-0.05858298-0.01718844j -0.01250759-0.05450939j\n",
      "   -0.00463034-0.02055064j -0.06269756+0.00962464j\n",
      "   -0.028055  -0.00648736j  0.03925508-0.01850148j]\n",
      "  [ 0.02123391+0.01986977j  0.07132129-0.00884751j\n",
      "    0.00219106+0.0435536j   0.01306577+0.00263045j\n",
      "   -0.02224062+0.02286002j  0.04074107+0.029647j  ]\n",
      "  [-0.04014112+0.02538899j -0.09337985+0.07869821j\n",
      "   -0.05127651+0.078045j   -0.04144546+0.07320954j\n",
      "    0.01083458+0.02729294j  0.05477095-0.15732123j]]\n",
      "\n",
      " [[-0.01625868+0.10053153j -0.09426332+0.09011439j\n",
      "   -0.05310619+0.06312911j -0.04254598+0.03524319j\n",
      "    0.01484631+0.04400401j -0.00608389-0.05257237j]\n",
      "  [-0.06478672+0.05285031j -0.00174515-0.0602091j\n",
      "   -0.07457652-0.022996j   -0.07918737+0.03370882j\n",
      "   -0.01400866+0.02355951j  0.02676228-0.01834389j]\n",
      "  [ 0.02914243-0.03063269j  0.02032438+0.07985848j\n",
      "    0.01922516+0.05486344j -0.04115096+0.02518727j\n",
      "    0.00797831-0.0308781j   0.02252918+0.04516778j]\n",
      "  [-0.01215947-0.0129074j   0.04237986-0.00338881j\n",
      "   -0.00172979-0.03639351j  0.05609513+0.04415435j\n",
      "    0.00380446-0.02768468j  0.02139488-0.01073172j]]\n",
      "\n",
      " [[-0.03703546-0.08766407j  0.04621471-0.0206918j\n",
      "    0.00347744+0.05001074j -0.02971773+0.01806054j\n",
      "   -0.04730311+0.00904878j  0.07979366-0.09390846j]\n",
      "  [-0.0750339 +0.01435942j -0.05242587+0.01385422j\n",
      "   -0.01477993+0.03273747j  0.00125408+0.06996751j\n",
      "    0.01187653+0.01444016j -0.03193324-0.11144951j]\n",
      "  [ 0.02288342-0.03879909j  0.00207033+0.14243522j\n",
      "    0.02138628+0.08393928j -0.01683809-0.01179839j\n",
      "    0.01725692-0.00539168j  0.01268613-0.00700677j]\n",
      "  [ 0.05528167+0.00510115j  0.02643114+0.00608434j\n",
      "    0.02206833+0.01108779j -0.00116313+0.02834514j\n",
      "    0.02439691-0.0131469j   0.10487219+0.00126861j]]\n",
      "\n",
      " [[ 0.0648995 -0.05808166j  0.06233524+0.01297915j\n",
      "    0.03619543+0.01178344j  0.0010052 +0.03756983j\n",
      "    0.02317186-0.00435178j  0.03967945-0.00392407j]\n",
      "  [ 0.01214627+0.04893243j -0.11822361+0.05890431j\n",
      "   -0.07534899+0.0258077j  -0.0479757 -0.01906915j\n",
      "   -0.0082792 +0.02288214j  0.01007854+0.04614258j]\n",
      "  [ 0.0587304 +0.0448622j   0.00661589-0.02664404j\n",
      "    0.01977336-0.03484207j  0.03295778-0.0658195j\n",
      "   -0.00599263+0.01382874j -0.06133392+0.07223196j]\n",
      "  [-0.11952069-0.04820868j  0.03133853-0.14193254j\n",
      "    0.01255181-0.03447982j  0.00806665-0.00434113j\n",
      "   -0.02631223-0.02621576j  0.04881225-0.0553319j ]]]\n",
      ">\n",
      "<npc.Array shape=(6, 4, 4) labels=['vLm', 'p', 'p*']\n",
      "charge=ChargeInfo([], [])\n",
      " -1 | +1 | -1 \n",
      "0 []|0 []|0 []\n",
      "6   |4   |4   \n",
      "[[[-2.75862348e-06+6.71789544e-06j -1.42603622e-06+9.27971951e-06j\n",
      "   -8.70325440e-07+7.78113715e-07j  1.17840099e-07+4.91599081e-07j]\n",
      "  [-1.02914773e-05+2.08745649e-05j  5.75622649e-07+1.08598586e-05j\n",
      "   -3.92394613e-07+1.77509075e-06j -9.39005568e-07+1.86014718e-07j]\n",
      "  [-4.14719515e-07-3.56662736e-07j -3.11240029e-07+7.58678524e-07j\n",
      "   -5.66521341e-06-1.70246492e-06j -3.45604734e-06-5.11785399e-06j]\n",
      "  [-3.60892243e-06+2.97707766e-06j  1.34895479e-06+5.22542766e-07j\n",
      "   -2.06282006e-06-1.72979500e-06j  3.57914992e-06-8.99208669e-06j]]\n",
      "\n",
      " [[-1.11460782e-05-9.31196352e-06j  6.82306405e-07-1.19659109e-05j\n",
      "   -4.07852887e-08-1.73059376e-06j  2.48581627e-06+9.65904956e-07j]\n",
      "  [-8.10648279e-07-1.07011469e-05j  5.62140681e-06-4.49558590e-06j\n",
      "   -2.60120228e-06-3.19014948e-06j  3.05603385e-07+7.54221433e-07j]\n",
      "  [-6.70085298e-07+7.03889338e-08j  5.57147410e-07+9.18498039e-08j\n",
      "   -3.13394360e-07-4.77789862e-07j  5.08141319e-06+1.25185830e-05j]\n",
      "  [ 8.84185329e-07-2.16393605e-06j  1.62045699e-07-5.06191437e-07j\n",
      "   -1.36768778e-07-1.51875120e-05j  1.09022783e-06+7.69635905e-07j]]\n",
      "\n",
      " [[-7.16093135e-06+4.42484258e-06j -1.32022074e-05+2.11127147e-06j\n",
      "   -6.93102834e-07-2.56843597e-07j -1.06708721e-06+2.12467594e-07j]\n",
      "  [-1.04061959e-05+9.40040294e-06j -1.37777321e-06+3.94356052e-06j\n",
      "   -1.26697578e-06+7.06238246e-07j -1.38242082e-07+1.08286872e-06j]\n",
      "  [-4.62597002e-07+6.77991856e-07j -1.86904463e-08+1.51509977e-06j\n",
      "   -5.74281004e-07+5.38340472e-06j  6.61564208e-08+1.17440809e-05j]\n",
      "  [ 7.20228846e-07+2.17943378e-06j -1.37493387e-07+6.62671649e-07j\n",
      "    6.31435210e-06+4.49077795e-06j -2.45621467e-06+6.11255350e-06j]]\n",
      "\n",
      " [[ 1.49348425e-06+9.65365063e-06j -3.80770427e-06+2.44572292e-05j\n",
      "   -8.33048954e-07+1.12584926e-06j -5.35179985e-07+2.58598749e-06j]\n",
      "  [ 4.48200525e-06-3.83321764e-06j  3.42715617e-06+1.79083635e-06j\n",
      "    1.11973625e-06-6.71889912e-07j  6.94721962e-07+6.32942187e-07j]\n",
      "  [ 9.71141555e-07-7.31052223e-08j -2.09222073e-07+6.30470748e-06j\n",
      "   -7.38473014e-06+8.65458011e-07j -3.70075893e-09+1.46391953e-05j]\n",
      "  [ 1.81133324e-08-1.40404473e-06j -9.05731039e-07-1.27477222e-07j\n",
      "   -2.47499257e-06-2.84131714e-07j -1.18322207e-06+6.74953828e-06j]]\n",
      "\n",
      " [[-6.30233814e-08+2.65831304e-06j  9.76991880e-06+2.42211528e-06j\n",
      "    7.02696659e-08-7.38137429e-07j  1.56671613e-06+1.52471764e-07j]\n",
      "  [-1.10520591e-05+5.20341721e-06j  2.27410068e-06-5.88262657e-07j\n",
      "   -9.51221039e-07+5.07945145e-07j  3.33733781e-07+6.45946378e-07j]\n",
      "  [ 3.32362229e-07+3.36790798e-07j  8.89146440e-08+1.48384115e-06j\n",
      "    2.18933414e-06-3.25532226e-06j -1.91292859e-06+6.06736578e-06j]\n",
      "  [-8.44023501e-07-9.59970768e-07j -1.79226120e-07-2.28209418e-07j\n",
      "    2.65574683e-06-8.85317007e-06j -2.71303784e-07+2.25739936e-07j]]\n",
      "\n",
      " [[ 8.12851311e-06-1.44040193e-05j  3.97236503e-06-1.31996714e-05j\n",
      "    1.41488469e-06-2.14196507e-08j -1.02270586e-06-1.48988846e-07j]\n",
      "  [ 9.25816197e-07-1.32009442e-05j -2.51266166e-06-6.23270906e-06j\n",
      "    2.00537780e-07-3.76950283e-07j  3.85686167e-07-1.52373670e-06j]\n",
      "  [ 2.09269921e-07-1.60426972e-06j  5.90072543e-07-2.30200140e-06j\n",
      "    2.46956550e-06+5.42021426e-07j -3.66346112e-06-6.55183964e-06j]\n",
      "  [-6.10246758e-08-1.64873221e-06j  2.39567957e-07+4.92794361e-07j\n",
      "    5.92661471e-06+1.04697614e-06j  9.30198368e-06-3.70942322e-06j]]]\n",
      ">\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "incompatible LegCharge\nself | other\n +1  |  -1  \n0 [] | 0 [] \n4    | 6    ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iterations):\n\u001b[0;32m---> 27\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mtwo_sided_mpo_rdm_gradient_descent_sweep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_mpo_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_mpo_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_b_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_b_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_total_dimension\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_total_dimension\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43msymmetry_transfer_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_adam_optimizers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_adam_optimizers\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(score)\n\u001b[1;32m     41\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[0;32mIn[59], line 31\u001b[0m, in \u001b[0;36mtwo_sided_mpo_rdm_gradient_descent_sweep\u001b[0;34m(left_mpo_tensors, right_mpo_tensors, left_b_tensors, right_b_tensors, left_total_dimension, right_total_dimension, symmetry_transfer_matrix, left_adam_optimizers, right_adam_optimizers)\u001b[0m\n\u001b[1;32m     24\u001b[0m left_symmetry_environment \u001b[38;5;241m=\u001b[39m npc\u001b[38;5;241m.\u001b[39mtensordot(\n\u001b[1;32m     25\u001b[0m     symmetry_transfer_matrix,\n\u001b[1;32m     26\u001b[0m     swap_left_right_indices(left_overlap_tensors[\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m     27\u001b[0m     [[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvL*\u001b[39m\u001b[38;5;124m'\u001b[39m], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvR*\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Get right gradients\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m right_grads, score \u001b[38;5;241m=\u001b[39m \u001b[43mmpo_rdm_gradient_descent_sweep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_mpo_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_b_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_total_dimension\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_overlap_tensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft_symmetry_environment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_adam_optimizers\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, g \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(right_grads):\n\u001b[1;32m     41\u001b[0m     right_mpo_tensors[i] \u001b[38;5;241m=\u001b[39m right_mpo_tensors[i] \u001b[38;5;241m-\u001b[39m g\n",
      "Cell \u001b[0;32mIn[64], line 45\u001b[0m, in \u001b[0;36mmpo_rdm_gradient_descent_sweep\u001b[0;34m(mpo_tensors, b_tensors, total_dimension, right_overlap_tensors, left_environment, adam_optimizers)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(grad_mpo)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(grad_o)\n\u001b[0;32m---> 45\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_mpo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgrad_o\u001b[49m\n\u001b[1;32m     47\u001b[0m score\u001b[38;5;241m=\u001b[39mupdate_mpo_score(\n\u001b[1;32m     48\u001b[0m     grad,\n\u001b[1;32m     49\u001b[0m     w,\n\u001b[1;32m     50\u001b[0m     [[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvLm\u001b[39m\u001b[38;5;124m'\u001b[39m,], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvR*\u001b[39m\u001b[38;5;124m'\u001b[39m,]],\n\u001b[1;32m     51\u001b[0m     take_abs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     52\u001b[0m )\n\u001b[1;32m     53\u001b[0m adam_grad \u001b[38;5;241m=\u001b[39m adam_optimizers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate(grad)\n",
      "File \u001b[0;32m~/.pyenv/versions/num_spt_venv_p11/lib/python3.11/site-packages/tenpy/linalg/np_conserved.py:2265\u001b[0m, in \u001b[0;36mArray.__sub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   2263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Array):\n\u001b[1;32m   2264\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 2265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miadd_prefactor_other\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/num_spt_venv_p11/lib/python3.11/site-packages/tenpy/linalg/_npc_helper.pyx:870\u001b[0m, in \u001b[0;36mtenpy.linalg._npc_helper.Array_iadd_prefactor_other\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/num_spt_venv_p11/lib/python3.11/site-packages/tenpy/linalg/charges.py:843\u001b[0m, in \u001b[0;36mLegCharge.test_equal\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m!=\u001b[39m other:\n\u001b[1;32m    842\u001b[0m     side_by_side \u001b[38;5;241m=\u001b[39m vert_join([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mother\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(other)], delim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 843\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible LegCharge\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m side_by_side)\n",
      "\u001b[0;31mValueError\u001b[0m: incompatible LegCharge\nself | other\n +1  |  -1  \n0 [] | 0 [] \n4    | 6    "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "(\n",
    "    left_mpo_tensors,\n",
    "    right_mpo_tensors,\n",
    "    left_b_tensors,\n",
    "    right_b_tensors,\n",
    "    left_total_dimension,\n",
    "    right_total_dimension,\n",
    "    _,\n",
    "    _,\n",
    "    symmetry_transfer_matrix,\n",
    "    left_adam_optimizers,\n",
    "    right_adam_optimizers\n",
    ") = initialize_optimization(\n",
    "    num_sites,\n",
    "    bond_dimension,\n",
    "    case,\n",
    "    1, #Unitarity learning rate\n",
    "    1,\n",
    "    adam_params\n",
    ")\n",
    "\n",
    "scores = list()\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    score = two_sided_mpo_rdm_gradient_descent_sweep(\n",
    "        left_mpo_tensors,\n",
    "        right_mpo_tensors,\n",
    "        left_b_tensors,\n",
    "        right_b_tensors,\n",
    "        left_total_dimension,\n",
    "        right_total_dimension,\n",
    "        symmetry_transfer_matrix,\n",
    "        left_adam_optimizers,\n",
    "        right_adam_optimizers\n",
    "    )\n",
    "\n",
    "    scores.append(score)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fdbbfd-b07d-416d-9f65-6dd008fe4c26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "num_spt_venv_p11",
   "language": "python",
   "name": "num_spt_venv_p11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
